{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Duplicate Application Dataset: Load, Canonicalize, and Generate Duplicates\n",
        "\n",
        "This notebook:\n",
        "- Loads the BPI Challenge 2012 XES log\n",
        "- Performs initial EDA for application events (A_*)\n",
        "- Builds canonical datasets (events.csv, applications.csv)\n",
        "- Provides a generator to synthesize duplicate applications of multiple types\n",
        "- Writes duplicate samples to data/processed/duplicate_samples.csv\n",
        "- Optionally builds a master duplicate-only dataset for downstream testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports and setup\n",
        "import pm4py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "plt.style.use('default')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "XES_PATH = 'data/BPI_Challenge_2012.xes'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading XES: data/BPI_Challenge_2012.xes\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34617f1d94cb46bb97fe2e8dc5fde000",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "parsing log, completed traces ::   0%|          | 0/13087 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved:\n",
            " - /Users/u.srinivasan/Documents/Projects_Garage/Duplicate-Invoice-Solution/data/processed/events.csv\n",
            " - /Users/u.srinivasan/Documents/Projects_Garage/Duplicate-Invoice-Solution/data/processed/applications.csv\n"
          ]
        }
      ],
      "source": [
        "# Create canonical events.csv and applications.csv from XES, including revenue/loan value\n",
        "import pm4py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "# Paths\n",
        "XES_PATH = 'data/BPI_Challenge_2012.xes'\n",
        "OUT_DIR = Path('data/processed')\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) Load XES → events (raw)\n",
        "print('Loading XES:', XES_PATH)\n",
        "log = pm4py.read_xes(XES_PATH)\n",
        "events = pm4py.convert_to_dataframe(log)\n",
        "\n",
        "# 2) Build applications view (A_* activities only)\n",
        "apps_df = events[events['concept:name'].str.startswith('A_', na=False)].copy()\n",
        "apps_df = apps_df[['case:concept:name','concept:name','org:resource','time:timestamp']].rename(columns={\n",
        "    'case:concept:name': 'application_id',\n",
        "    'concept:name': 'activity',\n",
        "    'org:resource': 'user',\n",
        "    'time:timestamp': 'timestamp'\n",
        "})\n",
        "\n",
        "# 2b) Add revenue/loan value if present\n",
        "# Try common column names, fallback to NaN if not found\n",
        "value_col = None\n",
        "for col in ['case:AMOUNT_REQ', 'case:loan_amount', 'case:revenue', 'case:AMOUNT', 'AMOUNT_REQ', 'loan_value', 'revenue']:\n",
        "    if col in events.columns:\n",
        "        value_col = col\n",
        "        break\n",
        "\n",
        "if value_col:\n",
        "    apps_df['value'] = events.loc[apps_df.index, value_col]\n",
        "else:\n",
        "    apps_df['value'] = np.nan\n",
        "\n",
        "# 3) Normalize types and timestamps\n",
        "def to_naive_dt(s):\n",
        "    s = pd.to_datetime(s, errors='coerce')\n",
        "    try:\n",
        "        s = s.dt.tz_convert(None)\n",
        "    except Exception:\n",
        "        try:\n",
        "            s = s.dt.tz_localize(None)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return s\n",
        "\n",
        "events['time:timestamp'] = to_naive_dt(events['time:timestamp'])\n",
        "if 'case:REG_DATE' in events.columns:\n",
        "    events['case:REG_DATE'] = to_naive_dt(events['case:REG_DATE'])\n",
        "\n",
        "apps_df['timestamp'] = to_naive_dt(apps_df['timestamp'])\n",
        "\n",
        "# 4) Applications case-level aggregates (include value)\n",
        "def normalize_app_number(x: str) -> str:\n",
        "    if pd.isna(x): return ''\n",
        "    s = str(x)\n",
        "    s = re.sub(r'^(APP|SYS|WEB|MOB|REF|REQ)', '', s, flags=re.IGNORECASE)\n",
        "    s = re.sub(r'^0+', '', s)\n",
        "    return s.lower()\n",
        "\n",
        "agg = (\n",
        "    apps_df.sort_values('timestamp')\n",
        "           .groupby('application_id', as_index=False)\n",
        "           .agg(\n",
        "               first_timestamp=('timestamp','first'),\n",
        "               last_timestamp=('timestamp','last'),\n",
        "               primary_user=('user','first'),\n",
        "               n_events=('activity','size'),\n",
        "               activity_sequence=('activity', lambda a: ' '.join(a.tolist())),\n",
        "               value=('value','first')  # take first value per application\n",
        "           )\n",
        ")\n",
        "agg['application_number'] = agg['application_id'].astype(str)\n",
        "agg['app_number_normalized'] = agg['application_number'].apply(normalize_app_number)\n",
        "\n",
        "applications = agg[['application_id','application_number','app_number_normalized',\n",
        "                    'first_timestamp','last_timestamp','primary_user','n_events','activity_sequence','value']]\n",
        "\n",
        "# 5) Sanitize for CSV (strings for objects)\n",
        "def sanitize_for_csv(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    for c in out.columns:\n",
        "        if out[c].dtype == 'object':\n",
        "            out[c] = out[c].astype(str)\n",
        "    return out\n",
        "\n",
        "events_out = sanitize_for_csv(events)\n",
        "applications_out = sanitize_for_csv(applications)\n",
        "\n",
        "# 6) Save CSVs\n",
        "events_csv = OUT_DIR / 'events.csv'\n",
        "applications_csv = OUT_DIR / 'applications.csv'\n",
        "events_out.to_csv(events_csv, index=False)\n",
        "applications_out.to_csv(applications_csv, index=False)\n",
        "\n",
        "print('Saved:')\n",
        "print(' -', events_csv.resolve())\n",
        "print(' -', applications_csv.resolve())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows per duplicate type:\n",
            "duplicate_type\n",
            "fuzzy_typo             20246\n",
            "fuzzy_insert_delete    16667\n",
            "fuzzy_transpose         6544\n",
            "nonfuzzy_prefix         2964\n",
            "nonfuzzy_semantic       1790\n",
            "nonfuzzy_zero_pad       1790\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Saved: /Users/u.srinivasan/Documents/Projects_Garage/Duplicate-Invoice-Solution/data/processed/duplicate_applications_master.csv\n",
            "Total rows: 50001\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_application_id</th>\n",
              "      <th>original_application_number</th>\n",
              "      <th>duplicate_application_number</th>\n",
              "      <th>duplicate_type</th>\n",
              "      <th>variation</th>\n",
              "      <th>expected_detection</th>\n",
              "      <th>primary_user_A</th>\n",
              "      <th>primary_user_B</th>\n",
              "      <th>first_timestamp_A</th>\n",
              "      <th>first_timestamp_B</th>\n",
              "      <th>activity_sequence_A</th>\n",
              "      <th>activity_sequence_B</th>\n",
              "      <th>amount_req_A</th>\n",
              "      <th>amount_req_B</th>\n",
              "      <th>string_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>188371</td>\n",
              "      <td>188371</td>\n",
              "      <td>1883711</td>\n",
              "      <td>fuzzy_insert_delete</td>\n",
              "      <td>insert_or_delete</td>\n",
              "      <td>fuzzy_detectable</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-11-23 10:42:16.720</td>\n",
              "      <td>2011-11-23 21:14:16.720</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_CANCELLED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_CANCELLED</td>\n",
              "      <td>30000</td>\n",
              "      <td>33246.151436</td>\n",
              "      <td>92.307692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>196048</td>\n",
              "      <td>196048</td>\n",
              "      <td>R196048</td>\n",
              "      <td>fuzzy_insert_delete</td>\n",
              "      <td>insert_or_delete</td>\n",
              "      <td>fuzzy_detectable</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-12-28 13:05:49.406</td>\n",
              "      <td>2011-12-28 13:36:49.406</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>300</td>\n",
              "      <td>295.890162</td>\n",
              "      <td>92.307692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>204604</td>\n",
              "      <td>204604</td>\n",
              "      <td>208604</td>\n",
              "      <td>fuzzy_typo</td>\n",
              "      <td>typo</td>\n",
              "      <td>fuzzy_detectable</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2012-01-28 13:30:36.915</td>\n",
              "      <td>2012-01-28 16:40:36.915</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_DECLINED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_DECLINED</td>\n",
              "      <td>5000</td>\n",
              "      <td>4799.221563</td>\n",
              "      <td>83.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>185437</td>\n",
              "      <td>185437</td>\n",
              "      <td>18543X7</td>\n",
              "      <td>fuzzy_insert_delete</td>\n",
              "      <td>insert_or_delete</td>\n",
              "      <td>fuzzy_detectable</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-11-15 09:00:34.480</td>\n",
              "      <td>2011-11-15 18:07:34.480</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>50000</td>\n",
              "      <td>50389.561158</td>\n",
              "      <td>92.307692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>177092</td>\n",
              "      <td>177092</td>\n",
              "      <td>137092</td>\n",
              "      <td>fuzzy_typo</td>\n",
              "      <td>typo</td>\n",
              "      <td>fuzzy_detectable</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-10-14 22:19:53.123</td>\n",
              "      <td>2011-10-15 06:46:53.123</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_CANCELLED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_CANCELLED</td>\n",
              "      <td>10000</td>\n",
              "      <td>10431.074865</td>\n",
              "      <td>83.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>188410</td>\n",
              "      <td>188410</td>\n",
              "      <td>18410</td>\n",
              "      <td>fuzzy_insert_delete</td>\n",
              "      <td>insert_or_delete</td>\n",
              "      <td>fuzzy_detectable</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-11-23 12:44:02.815</td>\n",
              "      <td>2011-11-23 21:59:02.815</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>5000</td>\n",
              "      <td>4931.983234</td>\n",
              "      <td>90.909091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>204496</td>\n",
              "      <td>204496</td>\n",
              "      <td>24496</td>\n",
              "      <td>fuzzy_insert_delete</td>\n",
              "      <td>insert_or_delete</td>\n",
              "      <td>fuzzy_detectable</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2012-01-27 17:47:59.852</td>\n",
              "      <td>2012-01-28 12:56:59.852</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED</td>\n",
              "      <td>30000</td>\n",
              "      <td>25269.416924</td>\n",
              "      <td>90.909091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>207322</td>\n",
              "      <td>207322</td>\n",
              "      <td>SYS0000207322</td>\n",
              "      <td>nonfuzzy_semantic</td>\n",
              "      <td>user_time_window</td>\n",
              "      <td>non_fuzzy_detectable</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2012-02-07 22:14:39.816</td>\n",
              "      <td>2012-02-07 23:04:39.816</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>2000</td>\n",
              "      <td>1904.926355</td>\n",
              "      <td>63.157895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>175302</td>\n",
              "      <td>175302</td>\n",
              "      <td>115302</td>\n",
              "      <td>fuzzy_typo</td>\n",
              "      <td>typo</td>\n",
              "      <td>fuzzy_detectable</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-10-07 11:46:03.522</td>\n",
              "      <td>2011-10-07 19:14:03.522</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_APPROVED A_REGISTERED A_ACTIVATED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_APPROVED A_REGISTERED A_ACTIVATED</td>\n",
              "      <td>20000</td>\n",
              "      <td>23859.772930</td>\n",
              "      <td>83.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>204400</td>\n",
              "      <td>204400</td>\n",
              "      <td>204400</td>\n",
              "      <td>fuzzy_transpose</td>\n",
              "      <td>transpose</td>\n",
              "      <td>fuzzy_detectable</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2012-01-27 10:46:55.693</td>\n",
              "      <td>2012-01-28 08:15:55.693</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_CANCELLED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_CANCELLED</td>\n",
              "      <td>17500</td>\n",
              "      <td>17993.136069</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  original_application_id original_application_number  \\\n",
              "0                  188371                      188371   \n",
              "1                  196048                      196048   \n",
              "2                  204604                      204604   \n",
              "3                  185437                      185437   \n",
              "4                  177092                      177092   \n",
              "5                  188410                      188410   \n",
              "6                  204496                      204496   \n",
              "7                  207322                      207322   \n",
              "8                  175302                      175302   \n",
              "9                  204400                      204400   \n",
              "\n",
              "  duplicate_application_number       duplicate_type         variation  \\\n",
              "0                      1883711  fuzzy_insert_delete  insert_or_delete   \n",
              "1                      R196048  fuzzy_insert_delete  insert_or_delete   \n",
              "2                       208604           fuzzy_typo              typo   \n",
              "3                      18543X7  fuzzy_insert_delete  insert_or_delete   \n",
              "4                       137092           fuzzy_typo              typo   \n",
              "5                        18410  fuzzy_insert_delete  insert_or_delete   \n",
              "6                        24496  fuzzy_insert_delete  insert_or_delete   \n",
              "7                SYS0000207322    nonfuzzy_semantic  user_time_window   \n",
              "8                       115302           fuzzy_typo              typo   \n",
              "9                       204400      fuzzy_transpose         transpose   \n",
              "\n",
              "     expected_detection primary_user_A primary_user_B       first_timestamp_A  \\\n",
              "0      fuzzy_detectable            112            112 2011-11-23 10:42:16.720   \n",
              "1      fuzzy_detectable            112            112 2011-12-28 13:05:49.406   \n",
              "2      fuzzy_detectable            112            112 2012-01-28 13:30:36.915   \n",
              "3      fuzzy_detectable            112            112 2011-11-15 09:00:34.480   \n",
              "4      fuzzy_detectable            112            112 2011-10-14 22:19:53.123   \n",
              "5      fuzzy_detectable            112            112 2011-11-23 12:44:02.815   \n",
              "6      fuzzy_detectable            112            112 2012-01-27 17:47:59.852   \n",
              "7  non_fuzzy_detectable            112            112 2012-02-07 22:14:39.816   \n",
              "8      fuzzy_detectable            112            112 2011-10-07 11:46:03.522   \n",
              "9      fuzzy_detectable            112            112 2012-01-27 10:46:55.693   \n",
              "\n",
              "        first_timestamp_B  \\\n",
              "0 2011-11-23 21:14:16.720   \n",
              "1 2011-12-28 13:36:49.406   \n",
              "2 2012-01-28 16:40:36.915   \n",
              "3 2011-11-15 18:07:34.480   \n",
              "4 2011-10-15 06:46:53.123   \n",
              "5 2011-11-23 21:59:02.815   \n",
              "6 2012-01-28 12:56:59.852   \n",
              "7 2012-02-07 23:04:39.816   \n",
              "8 2011-10-07 19:14:03.522   \n",
              "9 2012-01-28 08:15:55.693   \n",
              "\n",
              "                                                                                      activity_sequence_A  \\\n",
              "0                                                 A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_CANCELLED   \n",
              "1                                                                A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "2                           A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_DECLINED   \n",
              "3                                                                A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "4                          A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_CANCELLED   \n",
              "5                                                                A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "6                                      A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED   \n",
              "7                                                                A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "8  A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_APPROVED A_REGISTERED A_ACTIVATED   \n",
              "9                                                 A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_CANCELLED   \n",
              "\n",
              "                                                                                      activity_sequence_B  \\\n",
              "0                                                 A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_CANCELLED   \n",
              "1                                                                A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "2                           A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_DECLINED   \n",
              "3                                                                A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "4                          A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_CANCELLED   \n",
              "5                                                                A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "6                                      A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED   \n",
              "7                                                                A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "8  A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_APPROVED A_REGISTERED A_ACTIVATED   \n",
              "9                                                 A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_CANCELLED   \n",
              "\n",
              "   amount_req_A  amount_req_B  string_similarity  \n",
              "0         30000  33246.151436          92.307692  \n",
              "1           300    295.890162          92.307692  \n",
              "2          5000   4799.221563          83.333333  \n",
              "3         50000  50389.561158          92.307692  \n",
              "4         10000  10431.074865          83.333333  \n",
              "5          5000   4931.983234          90.909091  \n",
              "6         30000  25269.416924          90.909091  \n",
              "7          2000   1904.926355          63.157895  \n",
              "8         20000  23859.772930          83.333333  \n",
              "9         17500  17993.136069         100.000000  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate a scalable, comprehensive duplicate-applications dataset (all types) and save CSV\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import timedelta\n",
        "import random\n",
        "import re\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "# Config\n",
        "INPUT_APPS_CSV = 'data/processed/applications.csv'\n",
        "OUT_DIR = Path('data/processed')\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Size controls\n",
        "target_total = 50000\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "apps = pd.read_csv(\n",
        "    INPUT_APPS_CSV,\n",
        "    parse_dates=['first_timestamp','last_timestamp'],\n",
        "    dtype={'application_id': str, 'application_number': str, 'app_number_normalized': str}\n",
        ")\n",
        "\n",
        "# Ensure amount_req column exists (fallback to value if not)\n",
        "if 'amount_req' not in apps.columns:\n",
        "    if 'value' in apps.columns:\n",
        "        apps['amount_req'] = apps['value']\n",
        "    else:\n",
        "        apps['amount_req'] = np.nan\n",
        "\n",
        "# Helper generators (fuzzy)\n",
        "def typo_variation(s: str) -> str:\n",
        "    if not s: return s\n",
        "    i = random.randrange(len(s))\n",
        "    ch = s[i]\n",
        "    if ch.isdigit():\n",
        "        repl = str((int(ch) + random.randint(1, 9)) % 10)\n",
        "    else:\n",
        "        repl = chr(((ord(ch.lower()) - 97 + random.randint(1, 3)) % 26) + 97)\n",
        "    return s[:i] + repl + s[i+1:]\n",
        "\n",
        "def insert_or_delete(s: str) -> str:\n",
        "    if not s: return s\n",
        "    if random.random() < 0.5 and len(s) < 18:\n",
        "        i = random.randrange(len(s)+1)\n",
        "        add = random.choice('0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
        "        return s[:i] + add + s[i:]\n",
        "    if len(s) > 1:\n",
        "        i = random.randrange(len(s))\n",
        "        return s[:i] + s[i+1:]\n",
        "    return s\n",
        "\n",
        "def transpose_adjacent(s: str) -> str:\n",
        "    if len(s) < 2: return s\n",
        "    i = random.randrange(len(s)-1)\n",
        "    t = list(s); t[i], t[i+1] = t[i+1], t[i]\n",
        "    return ''.join(t)\n",
        "\n",
        "# Helper generators (non-fuzzy/semantic)\n",
        "def prefix_format(s: str) -> str:\n",
        "    pref = random.choice(['APP','SYS','WEB','MOB','REF','REQ'])\n",
        "    return f'{pref}{s}'\n",
        "\n",
        "def zero_pad(s: str, width: int = 10) -> str:\n",
        "    digits = ''.join([c for c in s if c.isdigit()]) or s\n",
        "    try:\n",
        "        return str(int(digits)).zfill(width)\n",
        "    except Exception:\n",
        "        return digits.zfill(width)\n",
        "\n",
        "def normalize(s: str) -> str:\n",
        "    s = re.sub(r'^(APP|SYS|WEB|MOB|REF|REQ)', '', str(s), flags=re.IGNORECASE)\n",
        "    s = re.sub(r'^0+', '', s)\n",
        "    return s.lower()\n",
        "\n",
        "def time_shift(dt, minutes_low, minutes_high):\n",
        "    if pd.isna(dt): dt = pd.Timestamp.now()\n",
        "    return dt + timedelta(minutes=random.randint(minutes_low, minutes_high))\n",
        "\n",
        "def pick_alt_user(primary_user: str, pool) -> str:\n",
        "    choices = [u for u in pool if u != str(primary_user)]\n",
        "    return random.choice(choices or pool)\n",
        "\n",
        "def amount_variation(amount):\n",
        "    # Add or subtract up to 5% for fuzzy, or up to 20% for non-fuzzy\n",
        "    if pd.isna(amount): return amount\n",
        "    if random.random() < 0.5:\n",
        "        return amount * (1 + random.uniform(-0.05, 0.05))  # fuzzy\n",
        "    else:\n",
        "        return amount * (1 + random.uniform(-0.2, 0.2))    # non-fuzzy\n",
        "\n",
        "def make_row(a, dup_num, dup_type, variation, user_b=None, ts_b=None, act_b=None, amt_b=None):\n",
        "    a_num = a['application_number']\n",
        "    ft_a = a['first_timestamp']\n",
        "    if ts_b is None:\n",
        "        ts_b = time_shift(ft_a, 5, 24*60)\n",
        "    if user_b is None:\n",
        "        user_b = a.get('primary_user', '')\n",
        "    if act_b is None:\n",
        "        act_b = a.get('activity_sequence', '')\n",
        "    if amt_b is None:\n",
        "        amt_b = amount_variation(a.get('amount_req', np.nan))\n",
        "    return {\n",
        "        'original_application_id': a['application_id'],\n",
        "        'original_application_number': a_num,\n",
        "        'duplicate_application_number': dup_num,\n",
        "        'duplicate_type': dup_type,\n",
        "        'variation': variation,\n",
        "        'expected_detection': 'fuzzy_detectable' if dup_type.startswith('fuzzy') else 'non_fuzzy_detectable',\n",
        "        'primary_user_A': str(a.get('primary_user','')),\n",
        "        'primary_user_B': str(user_b),\n",
        "        'first_timestamp_A': ft_a,\n",
        "        'first_timestamp_B': ts_b,\n",
        "        'activity_sequence_A': a.get('activity_sequence',''),\n",
        "        'activity_sequence_B': act_b,\n",
        "        'amount_req_A': a.get('amount_req', np.nan),\n",
        "        'amount_req_B': amt_b,\n",
        "        'string_similarity': fuzz.ratio(str(a_num), str(dup_num))\n",
        "    }\n",
        "\n",
        "def generate_dups(apps_df: pd.DataFrame, count_per_type: int) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    base = apps_df.sample(n=min(len(apps_df), count_per_type*6), random_state=seed).reset_index(drop=True)\n",
        "    users_pool = apps_df['primary_user'].dropna().astype(str).unique().tolist() or ['UserA','UserB','UserC']\n",
        "\n",
        "    # 1) Fuzzy: typo\n",
        "    for _, a in base.head(count_per_type).iterrows():\n",
        "        rows.append(make_row(a, typo_variation(a['application_number']), 'fuzzy_typo', 'typo'))\n",
        "\n",
        "    # 2) Fuzzy: insert/delete\n",
        "    for _, a in base.iloc[count_per_type:count_per_type*2].iterrows():\n",
        "        rows.append(make_row(a, insert_or_delete(a['application_number']), 'fuzzy_insert_delete', 'insert_or_delete'))\n",
        "\n",
        "    # 3) Fuzzy: transpose\n",
        "    for _, a in base.iloc[count_per_type*2:count_per_type*3].iterrows():\n",
        "        rows.append(make_row(a, transpose_adjacent(a['application_number']), 'fuzzy_transpose', 'transpose'))\n",
        "\n",
        "    # 4) Non-fuzzy: prefix/format\n",
        "    for _, a in base.iloc[count_per_type*3:count_per_type*4].iterrows():\n",
        "        rows.append(make_row(a, prefix_format(a['application_number']), 'nonfuzzy_prefix', 'prefix'))\n",
        "\n",
        "    # 5) Non-fuzzy: zero padding / re-encoding\n",
        "    for _, a in base.iloc[count_per_type*4:count_per_type*5].iterrows():\n",
        "        rows.append(make_row(a, zero_pad(a['application_number']), 'nonfuzzy_zero_pad', 'zero_pad'))\n",
        "\n",
        "    # 6) Non-fuzzy: semantic (alt user + similar time window, keep activities, vary amount)\n",
        "    for _, a in base.iloc[count_per_type*5:count_per_type*6].iterrows():\n",
        "        alt_user = pick_alt_user(a.get('primary_user',''), users_pool)\n",
        "        ts_b = time_shift(a.get('first_timestamp'), 10, 6*60)\n",
        "        dup_num = prefix_format(zero_pad(a['application_number']))\n",
        "        amt_b = amount_variation(a.get('amount_req', np.nan))\n",
        "        rows.append(make_row(a, dup_num, 'nonfuzzy_semantic', 'user_time_window', user_b=alt_user, ts_b=ts_b, amt_b=amt_b))\n",
        "\n",
        "    dup_df = pd.DataFrame(rows)\n",
        "    dup_df = dup_df.drop_duplicates(\n",
        "        subset=['original_application_number','duplicate_application_number'], keep='last'\n",
        "    ).reset_index(drop=True)\n",
        "    return dup_df\n",
        "\n",
        "per_type = max(1, target_total // 6)\n",
        "\n",
        "shards = []\n",
        "remaining = target_total\n",
        "while remaining > 0:\n",
        "    n = min(per_type, remaining // 6 if remaining >= 6 else 1)\n",
        "    if n == 0: break\n",
        "    shards.append(generate_dups(apps, n))\n",
        "    remaining -= len(shards[-1])\n",
        "\n",
        "dup_master = pd.concat(shards, ignore_index=True)\n",
        "dup_master = dup_master.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
        "\n",
        "print('Rows per duplicate type:')\n",
        "print(dup_master['duplicate_type'].value_counts())\n",
        "\n",
        "out_csv = OUT_DIR / 'duplicate_applications_master.csv'\n",
        "dup_master.to_csv(out_csv, index=False)\n",
        "print('\\nSaved:', out_csv.resolve())\n",
        "print('Total rows:', len(dup_master))\n",
        "dup_master.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /Users/u.srinivasan/Documents/Projects_Garage/Duplicate-Invoice-Solution/data/processed/applications_duplicates.csv\n",
            "Rows: 50001\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_id</th>\n",
              "      <th>application_number</th>\n",
              "      <th>app_number_normalized</th>\n",
              "      <th>first_timestamp</th>\n",
              "      <th>last_timestamp</th>\n",
              "      <th>primary_user</th>\n",
              "      <th>n_events</th>\n",
              "      <th>activity_sequence</th>\n",
              "      <th>amount_req</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1883711</td>\n",
              "      <td>1883711</td>\n",
              "      <td>1883711</td>\n",
              "      <td>2011-11-23 21:14:16.720</td>\n",
              "      <td>2011-11-23 21:34:16.720</td>\n",
              "      <td>112</td>\n",
              "      <td>4</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_CANCELLED</td>\n",
              "      <td>33246.151436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>R196048</td>\n",
              "      <td>R196048</td>\n",
              "      <td>r196048</td>\n",
              "      <td>2011-12-28 13:36:49.406</td>\n",
              "      <td>2011-12-28 13:51:49.406</td>\n",
              "      <td>112</td>\n",
              "      <td>3</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>295.890162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>208604</td>\n",
              "      <td>208604</td>\n",
              "      <td>208604</td>\n",
              "      <td>2012-01-28 16:40:36.915</td>\n",
              "      <td>2012-01-28 17:10:36.915</td>\n",
              "      <td>112</td>\n",
              "      <td>6</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_DECLINED</td>\n",
              "      <td>4799.221563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18543X7</td>\n",
              "      <td>18543X7</td>\n",
              "      <td>18543x7</td>\n",
              "      <td>2011-11-15 18:07:34.480</td>\n",
              "      <td>2011-11-15 18:22:34.480</td>\n",
              "      <td>112</td>\n",
              "      <td>3</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>50389.561158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>137092</td>\n",
              "      <td>137092</td>\n",
              "      <td>137092</td>\n",
              "      <td>2011-10-15 06:46:53.123</td>\n",
              "      <td>2011-10-15 07:16:53.123</td>\n",
              "      <td>112</td>\n",
              "      <td>6</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_CANCELLED</td>\n",
              "      <td>10431.074865</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  application_id application_number app_number_normalized  \\\n",
              "0        1883711            1883711               1883711   \n",
              "1        R196048            R196048               r196048   \n",
              "2         208604             208604                208604   \n",
              "3        18543X7            18543X7               18543x7   \n",
              "4         137092             137092                137092   \n",
              "\n",
              "          first_timestamp          last_timestamp primary_user  n_events  \\\n",
              "0 2011-11-23 21:14:16.720 2011-11-23 21:34:16.720          112         4   \n",
              "1 2011-12-28 13:36:49.406 2011-12-28 13:51:49.406          112         3   \n",
              "2 2012-01-28 16:40:36.915 2012-01-28 17:10:36.915          112         6   \n",
              "3 2011-11-15 18:07:34.480 2011-11-15 18:22:34.480          112         3   \n",
              "4 2011-10-15 06:46:53.123 2011-10-15 07:16:53.123          112         6   \n",
              "\n",
              "                                                                activity_sequence  \\\n",
              "0                         A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_CANCELLED   \n",
              "1                                        A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "2   A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_DECLINED   \n",
              "3                                        A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "4  A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_CANCELLED   \n",
              "\n",
              "     amount_req  \n",
              "0  33246.151436  \n",
              "1    295.890162  \n",
              "2   4799.221563  \n",
              "3  50389.561158  \n",
              "4  10431.074865  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert duplicate_applications_master.csv → applications-like structure and save (with amount_req)\n",
        "import pandas as pd\n",
        "import re\n",
        "from pathlib import Path\n",
        "from datetime import timedelta\n",
        "\n",
        "IN_DUP = 'data/processed/duplicate_applications_master.csv'   # from previous step\n",
        "OUT_DIR = Path('data/processed')\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OUT_CSV = OUT_DIR / 'applications_duplicates.csv'\n",
        "\n",
        "# Load\n",
        "dup = pd.read_csv(\n",
        "    IN_DUP,\n",
        "    parse_dates=['first_timestamp_A','first_timestamp_B'],\n",
        "    dtype={'original_application_id': str,\n",
        "           'original_application_number': str,\n",
        "           'duplicate_application_number': str}\n",
        ")\n",
        "\n",
        "# Helper: normalize application number (same rule used for applications.csv)\n",
        "def normalize_app_number(x: str) -> str:\n",
        "    if pd.isna(x): return ''\n",
        "    s = str(x)\n",
        "    s = re.sub(r'^(APP|SYS|WEB|MOB|REF|REQ)', '', s, flags=re.IGNORECASE)\n",
        "    s = re.sub(r'^0+', '', s)\n",
        "    return s.lower()\n",
        "\n",
        "# Derive required columns to match applications.csv schema:\n",
        "# ['application_id','application_number','app_number_normalized',\n",
        "#  'first_timestamp','last_timestamp','primary_user','n_events','activity_sequence','amount_req']\n",
        "out = pd.DataFrame()\n",
        "\n",
        "# Use the duplicate_application_number as both application_id and application_number (string)\n",
        "out['application_id'] = dup['duplicate_application_number'].astype(str)\n",
        "out['application_number'] = dup['duplicate_application_number'].astype(str)\n",
        "out['app_number_normalized'] = out['application_number'].apply(normalize_app_number)\n",
        "\n",
        "# Timestamps: use first_timestamp_B; synthesize last_timestamp by adding 5 minutes per event\n",
        "out['first_timestamp'] = dup['first_timestamp_B']\n",
        "\n",
        "# n_events from activity_sequence_B (fallback to 1 if empty)\n",
        "seq_b = dup['activity_sequence_B'].fillna('').astype(str)\n",
        "n_events = seq_b.apply(lambda s: max(1, len([t for t in s.split(' ') if t])))\n",
        "out['n_events'] = n_events\n",
        "\n",
        "# last_timestamp = first_timestamp + 5 minutes per event (minimum +5 minutes)\n",
        "duration_minutes_per_event = 5\n",
        "out['last_timestamp'] = out['first_timestamp'] + pd.to_timedelta(out['n_events'] * duration_minutes_per_event, unit='m')\n",
        "\n",
        "# primary_user from B\n",
        "out['primary_user'] = dup['primary_user_B'].astype(str)\n",
        "\n",
        "# activity_sequence from B\n",
        "out['activity_sequence'] = seq_b\n",
        "\n",
        "# amount_req from B (if present, else fallback to NaN)\n",
        "if 'amount_req_B' in dup.columns:\n",
        "    out['amount_req'] = dup['amount_req_B']\n",
        "elif 'value_B' in dup.columns:\n",
        "    out['amount_req'] = dup['value_B']\n",
        "else:\n",
        "    out['amount_req'] = np.nan\n",
        "\n",
        "# Optional: ensure column order exactly matches applications.csv (+ amount_req)\n",
        "out = out[['application_id','application_number','app_number_normalized',\n",
        "           'first_timestamp','last_timestamp','primary_user','n_events','activity_sequence','amount_req']]\n",
        "\n",
        "# Save\n",
        "out.to_csv(OUT_CSV, index=False)\n",
        "print('Saved:', OUT_CSV.resolve())\n",
        "print('Rows:', len(out))\n",
        "out.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded:\n",
            " - apps: 13087\n",
            " - candidates: 50001\n",
            " - apps amount_req present: True\n",
            " - candidates amount_req present: True\n"
          ]
        }
      ],
      "source": [
        "# Config and data load (run once)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import timedelta\n",
        "import re\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "pd.set_option('display.max_colwidth', 120)\n",
        "\n",
        "DATA_DIR = Path('data/processed')\n",
        "APPS = DATA_DIR / 'applications.csv'\n",
        "APPS_DUP = DATA_DIR / 'applications_duplicates.csv'  # treat as “unknown” new applications\n",
        "\n",
        "apps = pd.read_csv(\n",
        "    APPS,\n",
        "    parse_dates=['first_timestamp','last_timestamp'],\n",
        "    dtype={'application_id': str, 'application_number': str, 'app_number_normalized': str}\n",
        ")\n",
        "\n",
        "# Ensure amount_req column exists (fallback to value if not)\n",
        "if 'amount_req' not in apps.columns:\n",
        "    if 'value' in apps.columns:\n",
        "        apps['amount_req'] = apps['value']\n",
        "    else:\n",
        "        apps['amount_req'] = np.nan\n",
        "\n",
        "cand = pd.read_csv(\n",
        "    APPS_DUP,\n",
        "    parse_dates=['first_timestamp','last_timestamp'],\n",
        "    dtype={'application_id': str, 'application_number': str, 'app_number_normalized': str}\n",
        ")\n",
        "\n",
        "# Ensure amount_req column exists (fallback to value if not)\n",
        "if 'amount_req' not in cand.columns:\n",
        "    if 'value' in cand.columns:\n",
        "        cand['amount_req'] = cand['value']\n",
        "    else:\n",
        "        cand['amount_req'] = np.nan\n",
        "\n",
        "print('Loaded:')\n",
        "print(' - apps:', len(apps))\n",
        "print(' - candidates:', len(cand))\n",
        "print(' - apps amount_req present:', 'amount_req' in apps.columns)\n",
        "print(' - candidates amount_req present:', 'amount_req' in cand.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1) Data normalization and canonicalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_number</th>\n",
              "      <th>app_number_norm_v2</th>\n",
              "      <th>primary_user</th>\n",
              "      <th>first_timestamp</th>\n",
              "      <th>activity_sig_3</th>\n",
              "      <th>amount_req</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>173688</td>\n",
              "      <td>173688</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-10-01 00:38:44.546</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED</td>\n",
              "      <td>20000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>173691</td>\n",
              "      <td>173691</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-10-01 08:08:58.256</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>173694</td>\n",
              "      <td>173694</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-10-01 08:10:30.287</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED</td>\n",
              "      <td>7000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  application_number app_number_norm_v2 primary_user         first_timestamp  \\\n",
              "0             173688             173688          112 2011-10-01 00:38:44.546   \n",
              "1             173691             173691          112 2011-10-01 08:08:58.256   \n",
              "2             173694             173694          112 2011-10-01 08:10:30.287   \n",
              "\n",
              "                                activity_sig_3  amount_req  \n",
              "0  A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED       20000  \n",
              "1  A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED        5000  \n",
              "2  A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED        7000  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_number</th>\n",
              "      <th>app_number_norm_v2</th>\n",
              "      <th>primary_user</th>\n",
              "      <th>first_timestamp</th>\n",
              "      <th>activity_sig_3</th>\n",
              "      <th>amount_req</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1883711</td>\n",
              "      <td>1883711</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-11-23 21:14:16.720</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED</td>\n",
              "      <td>33246.151436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>R196048</td>\n",
              "      <td>r196048</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-12-28 13:36:49.406</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>295.890162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>208604</td>\n",
              "      <td>208604</td>\n",
              "      <td>112</td>\n",
              "      <td>2012-01-28 16:40:36.915</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED</td>\n",
              "      <td>4799.221563</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  application_number app_number_norm_v2 primary_user         first_timestamp  \\\n",
              "0            1883711            1883711          112 2011-11-23 21:14:16.720   \n",
              "1            R196048            r196048          112 2011-12-28 13:36:49.406   \n",
              "2             208604             208604          112 2012-01-28 16:40:36.915   \n",
              "\n",
              "                                activity_sig_3    amount_req  \n",
              "0  A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED  33246.151436  \n",
              "1     A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED    295.890162  \n",
              "2  A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED   4799.221563  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 1: Normalize keys and build canonical fields (with amount_req)\n",
        "\n",
        "def normalize_app_number(x: str) -> str:\n",
        "    if pd.isna(x): return ''\n",
        "    s = str(x)\n",
        "    s = re.sub(r'^(APP|SYS|WEB|MOB|REF|REQ)', '', s, flags=re.IGNORECASE)\n",
        "    s = re.sub(r'^0+', '', s)\n",
        "    return s.lower()\n",
        "\n",
        "def prep(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    out['application_number'] = out['application_number'].astype(str)\n",
        "    out['app_number_norm_v2'] = out['application_number'].apply(normalize_app_number)\n",
        "    out['primary_user'] = out['primary_user'].astype(str)\n",
        "    out['first_timestamp'] = pd.to_datetime(out['first_timestamp'], errors='coerce')\n",
        "    out['last_timestamp'] = pd.to_datetime(out['last_timestamp'], errors='coerce')\n",
        "    # simple activity signature\n",
        "    out['activity_seq'] = out['activity_sequence'].fillna('').astype(str)\n",
        "    out['activity_sig_3'] = out['activity_seq'].apply(lambda s: ' '.join(s.split()[:3]))\n",
        "    out['activity_len'] = out['activity_seq'].apply(lambda s: max(1, len(s.split())))\n",
        "    # Ensure amount_req exists\n",
        "    if 'amount_req' not in out.columns:\n",
        "        if 'value' in out.columns:\n",
        "            out['amount_req'] = out['value']\n",
        "        else:\n",
        "            out['amount_req'] = np.nan\n",
        "    return out\n",
        "\n",
        "apps1 = prep(apps)\n",
        "cand1 = prep(cand)\n",
        "\n",
        "# Sample results\n",
        "display(apps1.head(3)[['application_number','app_number_norm_v2','primary_user','first_timestamp','activity_sig_3','amount_req']])\n",
        "display(cand1.head(3)[['application_number','app_number_norm_v2','primary_user','first_timestamp','activity_sig_3','amount_req']])\n",
        "\n",
        "# --- Enhanced duplicate reasoning using amount_req ---\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "def strict_duplicate_reason(row, time_tolerance_hours=1, activity_similarity_threshold=80, amount_tolerance=0.01):\n",
        "    user_match = row['primary_user_cand'] == row['primary_user_apps']\n",
        "    time_diff = abs((row['first_timestamp_cand'] - row['first_timestamp_apps']).total_seconds()) / 3600\n",
        "    time_match = time_diff <= time_tolerance_hours\n",
        "    activity_sim = fuzz.ratio(str(row.get('activity_sequence_cand', '')), str(row.get('activity_sequence_apps', '')))\n",
        "    activity_match = activity_sim >= activity_similarity_threshold\n",
        "    # Amount match: within tolerance (default 1%)\n",
        "    amt_a = row.get('amount_req_cand', np.nan)\n",
        "    amt_b = row.get('amount_req_apps', np.nan)\n",
        "    if pd.notna(amt_a) and pd.notna(amt_b) and amt_a > 0:\n",
        "        amount_match = abs(amt_a - amt_b) / amt_a <= amount_tolerance\n",
        "    else:\n",
        "        amount_match = False\n",
        "    reasons = []\n",
        "    reasons.append(\"Primary user matches\" if user_match else \"Primary user does not match\")\n",
        "    reasons.append(f\"Timestamp within {time_tolerance_hours}h ({time_diff:.2f}h)\" if time_match else f\"Timestamp outside {time_tolerance_hours}h ({time_diff:.2f}h)\")\n",
        "    reasons.append(f\"Activity sequence similarity {activity_sim} ≥ {activity_similarity_threshold}\" if activity_match else f\"Activity sequence similarity {activity_sim} < {activity_similarity_threshold}\")\n",
        "    reasons.append(\"Amount matches\" if amount_match else \"Amount does not match\")\n",
        "    return \"; \".join(reasons)\n",
        "\n",
        "def false_positive_reason(row, activity_similarity_threshold=30, amount_tolerance=0.05):\n",
        "    user_mismatch = row['primary_user_cand'] != row['primary_user_apps']\n",
        "    activity_sim = fuzz.ratio(str(row.get('activity_sequence_cand', '')), str(row.get('activity_sequence_apps', '')))\n",
        "    activity_low = activity_sim < activity_similarity_threshold\n",
        "    amt_a = row.get('amount_req_cand', np.nan)\n",
        "    amt_b = row.get('amount_req_apps', np.nan)\n",
        "    if pd.notna(amt_a) and pd.notna(amt_b) and amt_a > 0:\n",
        "        amount_mismatch = abs(amt_a - amt_b) / amt_a > amount_tolerance\n",
        "    else:\n",
        "        amount_mismatch = True\n",
        "    reasons = []\n",
        "    reasons.append(\"Primary user does not match\" if user_mismatch else \"Primary user matches\")\n",
        "    reasons.append(f\"Activity sequence similarity {activity_sim} < {activity_similarity_threshold}\" if activity_low else f\"Activity sequence similarity {activity_sim} ≥ {activity_similarity_threshold}\")\n",
        "    reasons.append(\"Amount does not match\" if amount_mismatch else \"Amount matches\")\n",
        "    return \"; \".join(reasons)\n",
        "\n",
        "# When merging/joining, ensure amount_req columns are included for both cand1 and apps1\n",
        "# Example join for reasoning:\n",
        "# root_matches_full = root_matches.merge(\n",
        "#     cand1[['application_id', 'activity_sequence', 'amount_req']].rename(columns={'application_id': 'application_id_cand', 'activity_sequence': 'activity_sequence_cand', 'amount_req': 'amount_req_cand'}),\n",
        "#     on='application_id_cand', how='left'\n",
        "# ).merge(\n",
        "#     apps1[['application_id', 'activity_sequence', 'amount_req']].rename(columns={'application_id': 'application_id_apps', 'activity_sequence': 'activity_sequence_apps', 'amount_req': 'amount_req_apps'}),\n",
        "#     on='application_id_apps', how='left'\n",
        "# )\n",
        "\n",
        "# Now you can use strict_duplicate_reason and false_positive_reason for better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Strict duplicates after additional checks: 20\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_number_cand</th>\n",
              "      <th>application_number_apps</th>\n",
              "      <th>app_number_norm_v2</th>\n",
              "      <th>primary_user_cand</th>\n",
              "      <th>primary_user_apps</th>\n",
              "      <th>first_timestamp_cand</th>\n",
              "      <th>first_timestamp_apps</th>\n",
              "      <th>activity_sequence_cand</th>\n",
              "      <th>activity_sequence_apps</th>\n",
              "      <th>amount_req_cand</th>\n",
              "      <th>amount_req_apps</th>\n",
              "      <th>strict_duplicate_reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>REQ0000200308</td>\n",
              "      <td>200308</td>\n",
              "      <td>200308</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2012-01-12 17:29:58.356</td>\n",
              "      <td>2012-01-12 16:54:58.356</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>9962.049545</td>\n",
              "      <td>10000</td>\n",
              "      <td>Primary user matches; Timestamp within 1 hour(s) (0.58h); Activity sequence similarity 100.0 ≥ 80; Amount matches</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1617</th>\n",
              "      <td>0000190854</td>\n",
              "      <td>190854</td>\n",
              "      <td>190854</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-12-03 00:17:58.201</td>\n",
              "      <td>2011-12-03 00:12:58.201</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>2486.092171</td>\n",
              "      <td>2500</td>\n",
              "      <td>Primary user matches; Timestamp within 1 hour(s) (0.08h); Activity sequence similarity 100.0 ≥ 80; Amount matches</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2066</th>\n",
              "      <td>0000201436</td>\n",
              "      <td>201436</td>\n",
              "      <td>201436</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2012-01-16 19:12:45.783</td>\n",
              "      <td>2012-01-16 18:31:45.783</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_DECLINED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_DECLINED</td>\n",
              "      <td>4958.371012</td>\n",
              "      <td>5000</td>\n",
              "      <td>Primary user matches; Timestamp within 1 hour(s) (0.68h); Activity sequence similarity 100.0 ≥ 80; Amount matches</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2120</th>\n",
              "      <td>0000201623</td>\n",
              "      <td>201623</td>\n",
              "      <td>201623</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2012-01-17 10:55:41.215</td>\n",
              "      <td>2012-01-17 10:40:41.215</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED</td>\n",
              "      <td>14963.538587</td>\n",
              "      <td>15000</td>\n",
              "      <td>Primary user matches; Timestamp within 1 hour(s) (0.25h); Activity sequence similarity 100.0 ≥ 80; Amount matches</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2831</th>\n",
              "      <td>0000175012</td>\n",
              "      <td>175012</td>\n",
              "      <td>175012</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-10-06 12:00:32.215</td>\n",
              "      <td>2011-10-06 11:23:32.215</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_DECLINED</td>\n",
              "      <td>A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_DECLINED</td>\n",
              "      <td>49625.019308</td>\n",
              "      <td>50000</td>\n",
              "      <td>Primary user matches; Timestamp within 1 hour(s) (0.62h); Activity sequence similarity 100.0 ≥ 80; Amount matches</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     application_number_cand application_number_apps app_number_norm_v2  \\\n",
              "11             REQ0000200308                  200308             200308   \n",
              "1617              0000190854                  190854             190854   \n",
              "2066              0000201436                  201436             201436   \n",
              "2120              0000201623                  201623             201623   \n",
              "2831              0000175012                  175012             175012   \n",
              "\n",
              "     primary_user_cand primary_user_apps    first_timestamp_cand  \\\n",
              "11                 112               112 2012-01-12 17:29:58.356   \n",
              "1617               112               112 2011-12-03 00:17:58.201   \n",
              "2066               112               112 2012-01-16 19:12:45.783   \n",
              "2120               112               112 2012-01-17 10:55:41.215   \n",
              "2831               112               112 2011-10-06 12:00:32.215   \n",
              "\n",
              "        first_timestamp_apps  \\\n",
              "11   2012-01-12 16:54:58.356   \n",
              "1617 2011-12-03 00:12:58.201   \n",
              "2066 2012-01-16 18:31:45.783   \n",
              "2120 2012-01-17 10:40:41.215   \n",
              "2831 2011-10-06 11:23:32.215   \n",
              "\n",
              "                                                             activity_sequence_cand  \\\n",
              "11                                         A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "1617                                       A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "2066  A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_DECLINED   \n",
              "2120                                       A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "2831                         A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_DECLINED   \n",
              "\n",
              "                                                             activity_sequence_apps  \\\n",
              "11                                         A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "1617                                       A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "2066  A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_ACCEPTED A_FINALIZED A_DECLINED   \n",
              "2120                                       A_SUBMITTED A_PARTLYSUBMITTED A_DECLINED   \n",
              "2831                         A_SUBMITTED A_PARTLYSUBMITTED A_PREACCEPTED A_DECLINED   \n",
              "\n",
              "      amount_req_cand  amount_req_apps  \\\n",
              "11        9962.049545            10000   \n",
              "1617      2486.092171             2500   \n",
              "2066      4958.371012             5000   \n",
              "2120     14963.538587            15000   \n",
              "2831     49625.019308            50000   \n",
              "\n",
              "                                                                                                strict_duplicate_reason  \n",
              "11    Primary user matches; Timestamp within 1 hour(s) (0.58h); Activity sequence similarity 100.0 ≥ 80; Amount matches  \n",
              "1617  Primary user matches; Timestamp within 1 hour(s) (0.08h); Activity sequence similarity 100.0 ≥ 80; Amount matches  \n",
              "2066  Primary user matches; Timestamp within 1 hour(s) (0.68h); Activity sequence similarity 100.0 ≥ 80; Amount matches  \n",
              "2120  Primary user matches; Timestamp within 1 hour(s) (0.25h); Activity sequence similarity 100.0 ≥ 80; Amount matches  \n",
              "2831  Primary user matches; Timestamp within 1 hour(s) (0.62h); Activity sequence similarity 100.0 ≥ 80; Amount matches  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Definite false positives: 0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_number_cand</th>\n",
              "      <th>application_number_apps</th>\n",
              "      <th>app_number_norm_v2</th>\n",
              "      <th>primary_user_cand</th>\n",
              "      <th>primary_user_apps</th>\n",
              "      <th>first_timestamp_cand</th>\n",
              "      <th>first_timestamp_apps</th>\n",
              "      <th>activity_sequence_cand</th>\n",
              "      <th>activity_sequence_apps</th>\n",
              "      <th>amount_req_cand</th>\n",
              "      <th>amount_req_apps</th>\n",
              "      <th>false_positive_reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [application_number_cand, application_number_apps, app_number_norm_v2, primary_user_cand, primary_user_apps, first_timestamp_cand, first_timestamp_apps, activity_sequence_cand, activity_sequence_apps, amount_req_cand, amount_req_apps, false_positive_reason]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Remaining candidates for further checks: 49980\n",
            "Remaining apps for further checks: 13067\n",
            "\n",
            "Summary:\n",
            "True duplicates identified: 20\n",
            "False positives identified: 0\n",
            "Remaining maybe duplicate applications (candidates): 49980\n",
            "Remaining maybe duplicate applications (apps): 13067\n"
          ]
        }
      ],
      "source": [
        "# Merge activity_sequence and amount_req columns for comparison\n",
        "root_matches_full = root_matches.merge(\n",
        "    cand1[['application_id', 'activity_sequence', 'amount_req']].rename(columns={\n",
        "        'application_id': 'application_id_cand',\n",
        "        'activity_sequence': 'activity_sequence_cand',\n",
        "        'amount_req': 'amount_req_cand'\n",
        "    }),\n",
        "    on='application_id_cand', how='left'\n",
        ").merge(\n",
        "    apps1[['application_id', 'activity_sequence', 'amount_req']].rename(columns={\n",
        "        'application_id': 'application_id_apps',\n",
        "        'activity_sequence': 'activity_sequence_apps',\n",
        "        'amount_req': 'amount_req_apps'\n",
        "    }),\n",
        "    on='application_id_apps', how='left'\n",
        ")\n",
        "\n",
        "# Reasoning for strict duplicates (now includes amount_req)\n",
        "def strict_duplicate_reason(row, time_tolerance_hours=1, activity_similarity_threshold=80, amount_tolerance=0.01):\n",
        "    from rapidfuzz import fuzz\n",
        "    user_match = row['primary_user_cand'] == row['primary_user_apps']\n",
        "    time_diff = abs((row['first_timestamp_cand'] - row['first_timestamp_apps']).total_seconds()) / 3600\n",
        "    time_match = time_diff <= time_tolerance_hours\n",
        "    activity_sim = fuzz.ratio(str(row.get('activity_sequence_cand', '')), str(row.get('activity_sequence_apps', '')))\n",
        "    activity_match = activity_sim >= activity_similarity_threshold\n",
        "    amt_a = row.get('amount_req_cand', np.nan)\n",
        "    amt_b = row.get('amount_req_apps', np.nan)\n",
        "    if pd.notna(amt_a) and pd.notna(amt_b) and amt_a > 0:\n",
        "        amount_match = abs(amt_a - amt_b) / amt_a <= amount_tolerance\n",
        "    else:\n",
        "        amount_match = False\n",
        "    reasons = []\n",
        "    reasons.append(\"Primary user matches\" if user_match else \"Primary user does not match\")\n",
        "    reasons.append(f\"Timestamp within {time_tolerance_hours} hour(s) ({time_diff:.2f}h)\" if time_match else f\"Timestamp outside {time_tolerance_hours} hour(s) ({time_diff:.2f}h)\")\n",
        "    reasons.append(f\"Activity sequence similarity {activity_sim} ≥ {activity_similarity_threshold}\" if activity_match else f\"Activity sequence similarity {activity_sim} < {activity_similarity_threshold}\")\n",
        "    reasons.append(\"Amount matches\" if amount_match else \"Amount does not match\")\n",
        "    return \"; \".join(reasons)\n",
        "\n",
        "# Reasoning for false positives (now includes amount_req)\n",
        "def false_positive_reason(row, activity_similarity_threshold=30, amount_tolerance=0.05):\n",
        "    from rapidfuzz import fuzz\n",
        "    user_mismatch = row['primary_user_cand'] != row['primary_user_apps']\n",
        "    activity_sim = fuzz.ratio(str(row.get('activity_sequence_cand', '')), str(row.get('activity_sequence_apps', '')))\n",
        "    activity_low = activity_sim < activity_similarity_threshold\n",
        "    amt_a = row.get('amount_req_cand', np.nan)\n",
        "    amt_b = row.get('amount_req_apps', np.nan)\n",
        "    if pd.notna(amt_a) and pd.notna(amt_b) and amt_a > 0:\n",
        "        amount_mismatch = abs(amt_a - amt_b) / amt_a > amount_tolerance\n",
        "    else:\n",
        "        amount_mismatch = True\n",
        "    reasons = []\n",
        "    reasons.append(\"Primary user does not match\" if user_mismatch else \"Primary user matches\")\n",
        "    reasons.append(f\"Activity sequence similarity {activity_sim} < {activity_similarity_threshold}\" if activity_low else f\"Activity sequence similarity {activity_sim} ≥ {activity_similarity_threshold}\")\n",
        "    reasons.append(\"Amount does not match\" if amount_mismatch else \"Amount matches\")\n",
        "    return \"; \".join(reasons)\n",
        "\n",
        "# Apply strict duplicate check and reasoning (with amount_req)\n",
        "root_matches_full['is_strict_duplicate'] = root_matches_full.apply(\n",
        "    lambda row: (\n",
        "        row['primary_user_cand'] == row['primary_user_apps'] and\n",
        "        abs((row['first_timestamp_cand'] - row['first_timestamp_apps']).total_seconds()) / 3600 <= 1 and\n",
        "        __import__('rapidfuzz').fuzz.ratio(str(row.get('activity_sequence_cand', '')), str(row.get('activity_sequence_apps', ''))) >= 80 and\n",
        "        pd.notna(row.get('amount_req_cand', np.nan)) and pd.notna(row.get('amount_req_apps', np.nan)) and row.get('amount_req_cand', 0) > 0 and\n",
        "        abs(row.get('amount_req_cand', 0) - row.get('amount_req_apps', 0)) / row.get('amount_req_cand', 1) <= 0.01\n",
        "    ), axis=1\n",
        ")\n",
        "root_matches_full['strict_duplicate_reason'] = root_matches_full.apply(\n",
        "    lambda row: strict_duplicate_reason(row, time_tolerance_hours=1, activity_similarity_threshold=80, amount_tolerance=0.01), axis=1\n",
        ")\n",
        "\n",
        "strict_duplicates = root_matches_full[root_matches_full['is_strict_duplicate']].copy()\n",
        "\n",
        "print('Strict duplicates after additional checks:', len(strict_duplicates))\n",
        "display(strict_duplicates.head(5)[[\n",
        "    'application_number_cand','application_number_apps','app_number_norm_v2',\n",
        "    'primary_user_cand','primary_user_apps','first_timestamp_cand','first_timestamp_apps',\n",
        "    'activity_sequence_cand','activity_sequence_apps','amount_req_cand','amount_req_apps','strict_duplicate_reason'\n",
        "]])\n",
        "\n",
        "# Apply false positive check and reasoning (with amount_req)\n",
        "root_matches_full['is_false_positive'] = root_matches_full.apply(\n",
        "    lambda row: (\n",
        "        row['primary_user_cand'] != row['primary_user_apps'] and\n",
        "        __import__('rapidfuzz').fuzz.ratio(str(row.get('activity_sequence_cand', '')), str(row.get('activity_sequence_apps', ''))) < 30 and\n",
        "        pd.notna(row.get('amount_req_cand', np.nan)) and pd.notna(row.get('amount_req_apps', np.nan)) and row.get('amount_req_cand', 0) > 0 and\n",
        "        abs(row.get('amount_req_cand', 0) - row.get('amount_req_apps', 0)) / row.get('amount_req_cand', 1) > 0.05\n",
        "    ), axis=1\n",
        ")\n",
        "root_matches_full['false_positive_reason'] = root_matches_full.apply(\n",
        "    lambda row: false_positive_reason(row, activity_similarity_threshold=30, amount_tolerance=0.05), axis=1\n",
        ")\n",
        "\n",
        "false_positives = root_matches_full[root_matches_full['is_false_positive']].copy()\n",
        "\n",
        "print('Definite false positives:', len(false_positives))\n",
        "display(false_positives.head(5)[[\n",
        "    'application_number_cand','application_number_apps','app_number_norm_v2',\n",
        "    'primary_user_cand','primary_user_apps','first_timestamp_cand','first_timestamp_apps',\n",
        "    'activity_sequence_cand','activity_sequence_apps','amount_req_cand','amount_req_apps','false_positive_reason'\n",
        "]])\n",
        "\n",
        "# Remove all applications involved in strict duplicates or false positives from further checks\n",
        "exclude_cand_ids = set(strict_duplicates['application_id_cand']).union(false_positives['application_id_cand'])\n",
        "exclude_apps_ids = set(strict_duplicates['application_id_apps']).union(false_positives['application_id_apps'])\n",
        "\n",
        "maybe_cand1 = cand1[~cand1['application_id'].isin(exclude_cand_ids)].copy()\n",
        "maybe_apps1 = apps1[~apps1['application_id'].isin(exclude_apps_ids)].copy()\n",
        "\n",
        "print('Remaining candidates for further checks:', len(maybe_cand1))\n",
        "print('Remaining apps for further checks:', len(maybe_apps1))\n",
        "\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"True duplicates identified: {len(strict_duplicates)}\")\n",
        "print(f\"False positives identified: {len(false_positives)}\")\n",
        "print(f\"Remaining maybe duplicate applications (candidates): {len(maybe_cand1)}\")\n",
        "print(f\"Remaining maybe duplicate applications (apps): {len(maybe_apps1)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Randomly selected application: SYS184619\n",
            "Top 10 closest matches (by similarity score, including amount_req):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_number</th>\n",
              "      <th>app_number_norm_v2</th>\n",
              "      <th>primary_user</th>\n",
              "      <th>first_timestamp</th>\n",
              "      <th>amount_req</th>\n",
              "      <th>similarity_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3503</th>\n",
              "      <td>184619</td>\n",
              "      <td>184619</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-11-11 17:39:19.320</td>\n",
              "      <td>50000</td>\n",
              "      <td>98.956612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3176</th>\n",
              "      <td>183619</td>\n",
              "      <td>183619</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-11-09 22:04:29.897</td>\n",
              "      <td>50000</td>\n",
              "      <td>88.123279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>174629</td>\n",
              "      <td>174629</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-10-05 10:00:20.578</td>\n",
              "      <td>50000</td>\n",
              "      <td>77.289946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1526</th>\n",
              "      <td>178497</td>\n",
              "      <td>178497</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-10-20 09:56:22.308</td>\n",
              "      <td>50000</td>\n",
              "      <td>77.289946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5045</th>\n",
              "      <td>189406</td>\n",
              "      <td>189406</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-11-27 21:53:26.370</td>\n",
              "      <td>50000</td>\n",
              "      <td>77.289946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>182041</td>\n",
              "      <td>182041</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-11-03 18:18:35.150</td>\n",
              "      <td>50000</td>\n",
              "      <td>77.289946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2159</th>\n",
              "      <td>180499</td>\n",
              "      <td>180499</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-10-28 12:11:57.570</td>\n",
              "      <td>50000</td>\n",
              "      <td>77.289946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7985</th>\n",
              "      <td>198561</td>\n",
              "      <td>198561</td>\n",
              "      <td>112</td>\n",
              "      <td>2012-01-06 12:10:22.681</td>\n",
              "      <td>50000</td>\n",
              "      <td>77.289946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3457</th>\n",
              "      <td>184481</td>\n",
              "      <td>184481</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-11-11 11:51:47.118</td>\n",
              "      <td>50000</td>\n",
              "      <td>77.289946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3342</th>\n",
              "      <td>184132</td>\n",
              "      <td>184132</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-11-10 16:52:01.908</td>\n",
              "      <td>50000</td>\n",
              "      <td>77.289946</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     application_number app_number_norm_v2 primary_user  \\\n",
              "3503             184619             184619          112   \n",
              "3176             183619             183619          112   \n",
              "296              174629             174629          112   \n",
              "1526             178497             178497          112   \n",
              "5045             189406             189406          112   \n",
              "2663             182041             182041          112   \n",
              "2159             180499             180499          112   \n",
              "7985             198561             198561          112   \n",
              "3457             184481             184481          112   \n",
              "3342             184132             184132          112   \n",
              "\n",
              "             first_timestamp  amount_req  similarity_score  \n",
              "3503 2011-11-11 17:39:19.320       50000         98.956612  \n",
              "3176 2011-11-09 22:04:29.897       50000         88.123279  \n",
              "296  2011-10-05 10:00:20.578       50000         77.289946  \n",
              "1526 2011-10-20 09:56:22.308       50000         77.289946  \n",
              "5045 2011-11-27 21:53:26.370       50000         77.289946  \n",
              "2663 2011-11-03 18:18:35.150       50000         77.289946  \n",
              "2159 2011-10-28 12:11:57.570       50000         77.289946  \n",
              "7985 2012-01-06 12:10:22.681       50000         77.289946  \n",
              "3457 2011-11-11 11:51:47.118       50000         77.289946  \n",
              "3342 2011-11-10 16:52:01.908       50000         77.289946  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "# 1) Pick a random application from the remaining maybe pile\n",
        "random_app = maybe_cand1.sample(n=1, random_state=72).iloc[0]\n",
        "\n",
        "# 2) Compute similarity scores with all remaining apps, including amount_req\n",
        "def compute_similarity(row, ref_app):\n",
        "    # You can adjust weights as needed\n",
        "    id_score = fuzz.ratio(str(row['app_number_norm_v2']), str(ref_app['app_number_norm_v2']))\n",
        "    activity_score = fuzz.ratio(str(row['activity_seq']), str(ref_app['activity_seq']))\n",
        "    user_score = 100 if row['primary_user'] == ref_app['primary_user'] else 0\n",
        "    time_score = (1 - min(abs((row['first_timestamp'] - ref_app['first_timestamp']).total_seconds()) / (3600*24), 1)) * 100\n",
        "    # Amount similarity: 100 if within 1%, else decay linearly to 0 at 20% difference\n",
        "    amt_a = row.get('amount_req', np.nan)\n",
        "    amt_b = ref_app.get('amount_req', np.nan)\n",
        "    if pd.notna(amt_a) and pd.notna(amt_b) and amt_a > 0:\n",
        "        amt_diff = abs(amt_a - amt_b) / amt_a\n",
        "        if amt_diff <= 0.01:\n",
        "            amount_score = 100\n",
        "        elif amt_diff <= 0.2:\n",
        "            amount_score = 100 * (1 - (amt_diff - 0.01) / 0.19)\n",
        "        else:\n",
        "            amount_score = 0\n",
        "    else:\n",
        "        amount_score = 0\n",
        "    # Weighted sum (tune weights as needed)\n",
        "    score = (\n",
        "        0.65 * id_score +\n",
        "        0.35 * amount_score\n",
        "    )\n",
        "    return score\n",
        "\n",
        "maybe_apps1['similarity_score'] = maybe_apps1.apply(lambda row: compute_similarity(row, random_app), axis=1)\n",
        "\n",
        "# 3) Get top 20 matches for the selected application (now includes amount_req)\n",
        "top_matches = maybe_apps1.sort_values('similarity_score', ascending=False).head(50)\n",
        "\n",
        "print(f\"Randomly selected application: {random_app['application_number']}\")\n",
        "print(\"Top 10 closest matches (by similarity score, including amount_req):\")\n",
        "display(top_matches[['application_number','app_number_norm_v2','primary_user','first_timestamp','amount_req','similarity_score']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top matches with refined similarity > 80% (user, timestamp, activity sequence):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_number</th>\n",
              "      <th>app_number_norm_v2</th>\n",
              "      <th>primary_user</th>\n",
              "      <th>first_timestamp</th>\n",
              "      <th>amount_req</th>\n",
              "      <th>similarity_score</th>\n",
              "      <th>refined_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>184619</td>\n",
              "      <td>184619</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-11-11 17:39:19.320</td>\n",
              "      <td>50000</td>\n",
              "      <td>98.956612</td>\n",
              "      <td>91.958333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>184646</td>\n",
              "      <td>184646</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-11-11 18:58:56.114</td>\n",
              "      <td>50000</td>\n",
              "      <td>77.289946</td>\n",
              "      <td>86.699649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>184601</td>\n",
              "      <td>184601</td>\n",
              "      <td>112</td>\n",
              "      <td>2011-11-11 16:04:45.389</td>\n",
              "      <td>45000</td>\n",
              "      <td>73.747039</td>\n",
              "      <td>83.070925</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  application_number app_number_norm_v2 primary_user         first_timestamp  \\\n",
              "0             184619             184619          112 2011-11-11 17:39:19.320   \n",
              "1             184646             184646          112 2011-11-11 18:58:56.114   \n",
              "2             184601             184601          112 2011-11-11 16:04:45.389   \n",
              "\n",
              "   amount_req  similarity_score  refined_similarity  \n",
              "0       50000         98.956612           91.958333  \n",
              "1       50000         77.289946           86.699649  \n",
              "2       45000         73.747039           83.070925  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def refine_similarity(row, ref_app):\n",
        "    activity_score = fuzz.ratio(str(row['activity_seq']), str(ref_app['activity_seq']))\n",
        "    user_score = 100 if row['primary_user'] == ref_app['primary_user'] else 0\n",
        "    time_score = (1 - min(abs((row['first_timestamp'] - ref_app['first_timestamp']).total_seconds()) / (3600*24), 1)) * 100\n",
        "    # Weighted sum for refinement (adjust weights as needed)\n",
        "    score = (\n",
        "        0.4 * activity_score +\n",
        "        0.3 * user_score +\n",
        "        0.3 * time_score\n",
        "    )\n",
        "    return score\n",
        "\n",
        "top_matches['refined_similarity'] = top_matches.apply(lambda row: refine_similarity(row, random_app), axis=1)\n",
        "top_matches_refined = top_matches[top_matches['refined_similarity'] > 80].sort_values('refined_similarity', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"Top matches with refined similarity > 80% (user, timestamp, activity sequence):\")\n",
        "display(top_matches_refined[['application_number','app_number_norm_v2','primary_user','first_timestamp','amount_req','similarity_score','refined_similarity']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final filtered matches (last_timestamp, n_events):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_number</th>\n",
              "      <th>app_number_norm_v2</th>\n",
              "      <th>primary_user</th>\n",
              "      <th>first_timestamp</th>\n",
              "      <th>last_timestamp</th>\n",
              "      <th>n_events</th>\n",
              "      <th>amount_req</th>\n",
              "      <th>similarity_score</th>\n",
              "      <th>refined_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [application_number, app_number_norm_v2, primary_user, first_timestamp, last_timestamp, n_events, amount_req, similarity_score, refined_similarity]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Further filter top_matches_refined using last_timestamp, n_events, and activity_sig_3\n",
        "\n",
        "# 1. Filter by last_timestamp: within 1 day of the random_app\n",
        "filtered_by_last_ts = top_matches_refined[\n",
        "    (abs((top_matches_refined['last_timestamp'] - random_app['last_timestamp']).dt.total_seconds()) <= 3600*24)\n",
        "]\n",
        "\n",
        "# 2. Filter by n_events: difference no more than 1\n",
        "filtered_by_n_events = filtered_by_last_ts[\n",
        "    (abs(filtered_by_last_ts['n_events'] - random_app['n_events']) <= 2)\n",
        "]\n",
        "\n",
        "# 3. Filter by activity_sig_3: must match exactly\n",
        "filtered_final = filtered_by_n_events[\n",
        "    (filtered_by_n_events['activity_sig_3'] == random_app['activity_sig_3'])\n",
        "].reset_index(drop=True)\n",
        "\n",
        "print(\"Final filtered matches (last_timestamp, n_events, activity_sig_3):\")\n",
        "display(filtered_final[['application_number','app_number_norm_v2','primary_user','first_timestamp','last_timestamp','n_events','activity_sig_3','amount_req','similarity_score','refined_similarity']])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dcenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
